{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this(by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nimport torch\nimport torch.nn as N\nfrom torch.optim import Adam\nimport torch.nn.functional as F\nimport torch.optim as op\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dframe = pd.read_csv(\"../input/entity-annotated-corpus/ner.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dframe.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=dframe[['word','tag']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=[]\nlabel=[]\na=[]\nb=[]\nfor x in zip(df1.word,df1.tag):\n    \n    if x[0]!=\".\":\n        a.append(x[0])\n        b.append(x[1])\n    \n    else:\n        data.append(a)\n        label.append(b)\n        a=[]\n        b=[]\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1=data[:20000]\nlabel1=label[:20000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen=max(map(len,data1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words=set()\nfor i in data:\n    words.update(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word2idx=dict([(j,i+1) for i,j in enumerate(words)])\nidx2word=dict([(j,i) for i,j in word2idx.items()])\nidxdata=[[word2idx[j] for j in s] for s in data]\nlabel1=set()\nfor i in label:\n    label1.update(i)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word2idx['<pad>']=0\nidx2word[0]='<pad>'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label2idx=dict([(i,j+1) for j,i in enumerate(label1)])\nidx2label=dict([(i,j) for j,i in label2idx.items()])\nidxlabel=[[label2idx[k] for k in s] for s in label]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator(data,label,batchsize,nepochs):\n    maxlen=max(map(len,data))\n    nbatches=len(data)/batchsize\n    data=data[:int(nbatches*batchsize)]\n    label=label[:int(nbatches*batchsize)]\n    for i in range(nepochs):\n        idx=np.random.permutation(np.arange(nbatches*batchsize).astype(np.int))\n        data=data[idx]\n        label=label[idx]\n        \n        for j in range(int(nbatches)):\n            batchx=np.zeros((batchsize,maxlen))\n            batchy=np.zeros((batchsize,maxlen))\n            x=data[j*batchsize:(j+1)*batchsize]\n            y=label[j*batchsize:(j+1)*batchsize]\n            for m in range(batchsize):\n                batchx[m,:len(x[m])]=x[m]\n                batchy[m,:len(y[m])]=y[m]\n            \n            yield batchx,batchy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idxdata=np.array(idxdata)\nidxlabel=np.array(idxlabel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class model(N.Module):\n    def __init__(self,vocabsize,embeddingdim,hiddendim,outputdim):\n        super().__init__()\n        self.embedding=N.Embedding(vocabsize,embeddingdim)\n        self.drop1=N.Dropout(0.2)\n        self.lstm=N.LSTM(embeddingdim,hiddendim,num_layers=2)\n        self.fc=N.Linear(hiddendim,outputdim)\n        \n    def forward(self,x):\n        embeds=self.embedding(x)\n        #print(embeds.shape)\n        embeds=self.drop1(embeds.permute(1,0,2))\n        out1=self.lstm(embeds)   # seqlen x batchsize x \n        #print(out1[0].shape)\n        out=self.fc(out1[0].permute(1,0,2))\n        #print(out.shape)\n        return out\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label2idx['<pad>']=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx2label[0]='<pad>'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocabsize=len(idx2word)\nembeddim=164\nhiddendim=256\noutputdim=len(label2idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1=model(vocabsize,embeddim,hiddendim,outputdim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count(model1):\n    return sum([l.numel() for l in model1.parameters()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count(model1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer=op.Adam(model1.parameters(),lr=0.0001)\nloss=N.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nepochs=2\nbatchsize=100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen1=generator(idxdata,idxlabel,batchsize,nepochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1=model1.to(device)\nloss=loss.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainloss=[]\ncount=0\nfor i in range(nepochs):\n    for j in range(int(len(idxdata)/batchsize)):\n        batchx,batchy=next(gen1)\n       \n        batchx1=torch.from_numpy(batchx).long()\n        batchy1=torch.from_numpy(batchy).long()\n        #print(batchx1)\n        optimizer.zero_grad()\n        batchx1=batchx1.to(device)  # very important to move tensors on gpu on which computations are taking place\n        batchy1=batchy1.to(device)  # we moved the model and all tensors for computation on gpu\n        output=model1.forward(batchx1)\n        \n        print(output.shape)\n        print(batchy1.shape)\n        l=loss(output.view(-1,19),batchy1.view(-1,)) #this is really important actual values should be of  shape (N), while pred (N,c)\n        l.backward()\n        optimizer.step()\n        print(\"loss is:-\",l,\" and epoch is:-\",i,\" count is \",j)\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}